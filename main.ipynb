{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-01T07:15:44.557536Z",
     "start_time": "2024-08-01T07:15:43.272181Z"
    }
   },
   "source": [
    "from coreset.decision_tree import dt_coreset\n",
    "from coreset.utils.formats import SparseData\n",
    "from data.datasets import get_circles, get_air_quality,get_moons, quantize_data,get_gesture_phase\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.utils import resample"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T07:15:44.562969Z",
     "start_time": "2024-08-01T07:15:44.559604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def scale_data(X, Y):\n",
    "    # with_mean= False could help\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    Y = scaler.fit_transform(Y.reshape((-1, 1)))[:, 0]\n",
    "    return X, Y"
   ],
   "id": "15bf228f3b2eea35",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T07:15:44.569572Z",
     "start_time": "2024-08-01T07:15:44.564193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_on_full_data(X_train, Y_train, X_test, Y_test, k):\n",
    "    ''' Model training on full data to compare with coreset results,\n",
    "        returns mean squared error on the testing set after training\n",
    "        on the full training dataset '''\n",
    "    model = RandomForestRegressor(max_leaf_nodes=k,n_jobs=-1,random_state=1)\n",
    "    model.fit(X_train, Y_train)\n",
    "    Y_pred = model.predict(X_test)\n",
    "    return mean_squared_error(Y_test, Y_pred)"
   ],
   "id": "50194831805bd80",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T07:15:44.575495Z",
     "start_time": "2024-08-01T07:15:44.571105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_on_coreset(coreset, X_train, Y_train, X_test, Y_test, k):\n",
    "    ''' Model training on coreset, returns mean squared error on the\n",
    "        testing set after training on a subset of the training dataset '''\n",
    "    X_coreset, Y_coreset, weights = coreset.X, coreset.Y, coreset.weights\n",
    "    model_coreset = RandomForestRegressor(max_leaf_nodes=k,n_jobs=-1,random_state=1)\n",
    "    model_coreset.fit(X_coreset, Y_coreset, sample_weight=weights)\n",
    "    Y_pred_coreset = model_coreset.predict(X_test)\n",
    "    return mean_squared_error(Y_test, Y_pred_coreset)"
   ],
   "id": "832c9325fc3f79ba",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T07:15:44.581263Z",
     "start_time": "2024-08-01T07:15:44.577434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def hyperparameter_tuning(X_train, Y_train, X_test, Y_test, param_grid):\n",
    "    rf = RandomForestRegressor(n_jobs=-1, random_state=1)\n",
    "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X_train, Y_train)\n",
    "\n",
    "    best_k = grid_search.best_params_['max_leaf_nodes']\n",
    "    print(f\"Best k value: {best_k}\")\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    Y_pred = best_model.predict(X_test)\n",
    "    mse = mean_squared_error(Y_test, Y_pred)\n",
    "    print(f\"Mean Squared Error with best k: {mse}\")"
   ],
   "id": "8b945939070d5201",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T07:16:41.820383Z",
     "start_time": "2024-08-01T07:15:44.582947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # X,Y=get_air_quality(3000)\n",
    "    # X,Y=get_circles(24000,10000)\n",
    "    X,Y=get_gesture_phase(3000)\n",
    "    X, Y = scale_data(X, Y)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "    data_train = SparseData(X_train, Y_train)\n",
    "    \n",
    "    # epsilons for air quality\n",
    "    epsilons=[0.0045, 0.0079, 0.016, 0.0165, 0.0194,0.0254 , 0.0266, 0.0328 , 0.0368, 0.0369, 0.04]\n",
    "    # epsilons for circle\n",
    "    # epsilons=[0.01,0.2,0.4,0.6]\n",
    "    k_values = [2000]\n",
    "    k=2000\n",
    "    coreset_verbose = True \n",
    "    use_exact_bicriteria_values=[True]\n",
    "    error_full = evaluate_on_full_data(X_train, Y_train, X_test, Y_test, k)\n",
    "    for use_exact_bicriteria in use_exact_bicriteria_values:\n",
    "        print(\"\\nConstructing coresets using exact bicriteria: {}\\n\".format(\n",
    "            use_exact_bicriteria))\n",
    "        for epsilon in epsilons:\n",
    "            print(\"\\nConstructing coreset for epsilon = {}\\n\".format(epsilon))\n",
    "            for k in k_values:\n",
    "                print(\"\\nConstructing coreset for k = {}\\n\".format(k))\n",
    "                # coreset construction\n",
    "                coreset, coreset_smoothed = dt_coreset(\n",
    "                    data_train, k, epsilon, verbose=coreset_verbose,\n",
    "                    use_exact_bicriteria=use_exact_bicriteria)\n",
    "\n",
    "                # error_coreset=0\n",
    "                # error_coreset_smoothed=0\n",
    "                # for i in range(10):\n",
    "                #     error_coreset += evaluate_on_coreset(\n",
    "                #         coreset, X_train, Y_train, X_test, Y_test, k)*0.1\n",
    "                #     error_coreset_smoothed += evaluate_on_coreset(\n",
    "                #         coreset_smoothed, X_train, Y_train, X_test, Y_test, k)*0.1\n",
    "                error_coreset=evaluate_on_coreset(coreset, X_train, Y_train, X_test, Y_test, k)\n",
    "                error_coreset_smoothed=evaluate_on_coreset(coreset_smoothed, X_train, Y_train, X_test, Y_test, k)\n",
    "\n",
    "                print((\"Using 100% of the training set ({} examples):\\n\" +\n",
    "                       \"\\tTesting error (full data):\\t\\t{:.5f}\").format(\n",
    "                          len(X_train), error_full))\n",
    "                print((\"Using {:.2f}% of the training set \" +\n",
    "                      \" (coreset of {} examples):\").format(\n",
    "                          coreset.size / float(len(X_train)) * 100,\n",
    "                          coreset.size))\n",
    "                \n",
    "                # pick a uniform sample of the size of the coreset from full data and train on it. then calculate the error on in\n",
    "                uniform_sample_indices=np.random.choice(len(X_train),coreset.size,replace=False)\n",
    "                X_uniform_sample = X_train[uniform_sample_indices]\n",
    "                Y_uniform_sample = Y_train[uniform_sample_indices]\n",
    "                error_uniform_sample = evaluate_on_full_data(X_uniform_sample, Y_uniform_sample, X_test, Y_test, k)\n",
    "\n",
    "                    \n",
    "                print(\"\\tTesting error (original coreset):\\t{:.5f}\".format(\n",
    "                      error_coreset))\n",
    "                print(\"\\tTesting error (smoothed coreset):\\t{:.5f}\".format(\n",
    "                      error_coreset_smoothed))\n",
    "                print(\"\\tTesting error (uniform sample):\\t\\t{:.5f}\".format(error_uniform_sample))\n",
    "                # save results to csv\n",
    "                with open(\"./Results/top_GP_rf.csv\", \"a\") as f:\n",
    "                    f.write(\"{},{},{},{},{},{},{}\\n\".format(epsilon,k, coreset.size,error_full, error_coreset, error_coreset_smoothed,error_uniform_sample))\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ],
   "id": "6a5de5db30072f50",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Constructing coresets using exact bicriteria: True\n",
      "\n",
      "\n",
      "Constructing coreset for epsilon = 0.0045\n",
      "\n",
      "\n",
      "Constructing coreset for k = 2000\n",
      "\n",
      "Expected approximate coreset size: 49383\n",
      "bicriteria: epsilon=0.0045 sigma=35144.94978803002\n",
      "bicriteria segments:  2000\n",
      "balanced partition: alpha = 1.00000, beta = 1.00000,gamma = 0.00450, sigma = 35144.94979:\n",
      "balanced partition segments: 2080\n",
      "Using 100% of the training set (142444 examples):\n",
      "\tTesting error (full data):\t\t0.31302\n",
      "Using 5.83% of the training set  (coreset of 8300 examples):\n",
      "\tTesting error (original coreset):\t0.68053\n",
      "\tTesting error (smoothed coreset):\t0.79320\n",
      "\tTesting error (uniform sample):\t\t0.46777\n",
      "\n",
      "Constructing coreset for epsilon = 0.0079\n",
      "\n",
      "\n",
      "Constructing coreset for k = 2000\n",
      "\n",
      "Expected approximate coreset size: 16024\n",
      "bicriteria: epsilon=0.0079 sigma=35144.94978803002\n",
      "bicriteria segments:  2000\n",
      "balanced partition: alpha = 1.00000, beta = 1.00000,gamma = 0.00790, sigma = 35144.94979:\n",
      "balanced partition segments: 1316\n",
      "Using 100% of the training set (142444 examples):\n",
      "\tTesting error (full data):\t\t0.31302\n",
      "Using 3.69% of the training set  (coreset of 5263 examples):\n",
      "\tTesting error (original coreset):\t0.74165\n",
      "\tTesting error (smoothed coreset):\t0.83790\n",
      "\tTesting error (uniform sample):\t\t0.47207\n",
      "\n",
      "Constructing coreset for epsilon = 0.016\n",
      "\n",
      "\n",
      "Constructing coreset for k = 2000\n",
      "\n",
      "Expected approximate coreset size: 3907\n",
      "bicriteria: epsilon=0.016 sigma=35144.94978803002\n",
      "bicriteria segments:  2000\n",
      "balanced partition: alpha = 1.00000, beta = 1.00000,gamma = 0.01600, sigma = 35144.94979:\n",
      "balanced partition segments: 782\n",
      "Using 100% of the training set (142444 examples):\n",
      "\tTesting error (full data):\t\t0.31302\n",
      "Using 2.20% of the training set  (coreset of 3127 examples):\n",
      "\tTesting error (original coreset):\t0.76000\n",
      "\tTesting error (smoothed coreset):\t0.85483\n",
      "\tTesting error (uniform sample):\t\t0.48709\n",
      "\n",
      "Constructing coreset for epsilon = 0.0165\n",
      "\n",
      "\n",
      "Constructing coreset for k = 2000\n",
      "\n",
      "Expected approximate coreset size: 3674\n",
      "bicriteria: epsilon=0.0165 sigma=35144.94978803002\n",
      "bicriteria segments:  2000\n",
      "balanced partition: alpha = 1.00000, beta = 1.00000,gamma = 0.01650, sigma = 35144.94979:\n",
      "balanced partition segments: 767\n",
      "Using 100% of the training set (142444 examples):\n",
      "\tTesting error (full data):\t\t0.31302\n",
      "Using 2.15% of the training set  (coreset of 3068 examples):\n",
      "\tTesting error (original coreset):\t0.77115\n",
      "\tTesting error (smoothed coreset):\t0.90310\n",
      "\tTesting error (uniform sample):\t\t0.49826\n",
      "\n",
      "Constructing coreset for epsilon = 0.0194\n",
      "\n",
      "\n",
      "Constructing coreset for k = 2000\n",
      "\n",
      "Expected approximate coreset size: 2658\n",
      "bicriteria: epsilon=0.0194 sigma=35144.94978803002\n",
      "bicriteria segments:  2000\n",
      "balanced partition: alpha = 1.00000, beta = 1.00000,gamma = 0.01940, sigma = 35144.94979:\n",
      "balanced partition segments: 697\n",
      "Using 100% of the training set (142444 examples):\n",
      "\tTesting error (full data):\t\t0.31302\n",
      "Using 1.96% of the training set  (coreset of 2786 examples):\n",
      "\tTesting error (original coreset):\t0.72507\n",
      "\tTesting error (smoothed coreset):\t0.88212\n",
      "\tTesting error (uniform sample):\t\t0.49130\n",
      "\n",
      "Constructing coreset for epsilon = 0.0254\n",
      "\n",
      "\n",
      "Constructing coreset for k = 2000\n",
      "\n",
      "Expected approximate coreset size: 1551\n",
      "bicriteria: epsilon=0.0254 sigma=35144.94978803002\n",
      "bicriteria segments:  2000\n",
      "balanced partition: alpha = 1.00000, beta = 1.00000,gamma = 0.02540, sigma = 35144.94979:\n",
      "balanced partition segments: 628\n",
      "Using 100% of the training set (142444 examples):\n",
      "\tTesting error (full data):\t\t0.31302\n",
      "Using 1.76% of the training set  (coreset of 2512 examples):\n",
      "\tTesting error (original coreset):\t0.72377\n",
      "\tTesting error (smoothed coreset):\t0.87231\n",
      "\tTesting error (uniform sample):\t\t0.49044\n",
      "\n",
      "Constructing coreset for epsilon = 0.0266\n",
      "\n",
      "\n",
      "Constructing coreset for k = 2000\n",
      "\n",
      "Expected approximate coreset size: 1414\n",
      "bicriteria: epsilon=0.0266 sigma=35144.94978803002\n",
      "bicriteria segments:  2000\n",
      "balanced partition: alpha = 1.00000, beta = 1.00000,gamma = 0.02660, sigma = 35144.94979:\n",
      "balanced partition segments: 621\n",
      "Using 100% of the training set (142444 examples):\n",
      "\tTesting error (full data):\t\t0.31302\n",
      "Using 1.74% of the training set  (coreset of 2482 examples):\n",
      "\tTesting error (original coreset):\t0.72694\n",
      "\tTesting error (smoothed coreset):\t0.86244\n",
      "\tTesting error (uniform sample):\t\t0.47188\n",
      "\n",
      "Constructing coreset for epsilon = 0.0328\n",
      "\n",
      "\n",
      "Constructing coreset for k = 2000\n",
      "\n",
      "Expected approximate coreset size: 930\n",
      "bicriteria: epsilon=0.0328 sigma=35144.94978803002\n",
      "bicriteria segments:  2000\n",
      "balanced partition: alpha = 1.00000, beta = 1.00000,gamma = 0.03280, sigma = 35144.94979:\n",
      "balanced partition segments: 574\n",
      "Using 100% of the training set (142444 examples):\n",
      "\tTesting error (full data):\t\t0.31302\n",
      "Using 1.61% of the training set  (coreset of 2296 examples):\n",
      "\tTesting error (original coreset):\t0.72936\n",
      "\tTesting error (smoothed coreset):\t0.84042\n",
      "\tTesting error (uniform sample):\t\t0.48166\n",
      "\n",
      "Constructing coreset for epsilon = 0.0368\n",
      "\n",
      "\n",
      "Constructing coreset for k = 2000\n",
      "\n",
      "Expected approximate coreset size: 739\n",
      "bicriteria: epsilon=0.0368 sigma=35144.94978803002\n",
      "bicriteria segments:  2000\n",
      "balanced partition: alpha = 1.00000, beta = 1.00000,gamma = 0.03680, sigma = 35144.94979:\n",
      "balanced partition segments: 515\n",
      "Using 100% of the training set (142444 examples):\n",
      "\tTesting error (full data):\t\t0.31302\n",
      "Using 1.45% of the training set  (coreset of 2060 examples):\n",
      "\tTesting error (original coreset):\t0.68883\n",
      "\tTesting error (smoothed coreset):\t0.80766\n",
      "\tTesting error (uniform sample):\t\t0.48479\n",
      "\n",
      "Constructing coreset for epsilon = 0.0369\n",
      "\n",
      "\n",
      "Constructing coreset for k = 2000\n",
      "\n",
      "Expected approximate coreset size: 735\n",
      "bicriteria: epsilon=0.0369 sigma=35144.94978803002\n",
      "bicriteria segments:  2000\n",
      "balanced partition: alpha = 1.00000, beta = 1.00000,gamma = 0.03690, sigma = 35144.94979:\n",
      "balanced partition segments: 525\n",
      "Using 100% of the training set (142444 examples):\n",
      "\tTesting error (full data):\t\t0.31302\n",
      "Using 1.47% of the training set  (coreset of 2100 examples):\n",
      "\tTesting error (original coreset):\t0.70674\n",
      "\tTesting error (smoothed coreset):\t0.80408\n",
      "\tTesting error (uniform sample):\t\t0.48621\n",
      "\n",
      "Constructing coreset for epsilon = 0.04\n",
      "\n",
      "\n",
      "Constructing coreset for k = 2000\n",
      "\n",
      "Expected approximate coreset size: 625\n",
      "bicriteria: epsilon=0.04 sigma=35144.94978803002\n",
      "bicriteria segments:  2000\n",
      "balanced partition: alpha = 1.00000, beta = 1.00000,gamma = 0.04000, sigma = 35144.94979:\n",
      "balanced partition segments: 491\n",
      "Using 100% of the training set (142444 examples):\n",
      "\tTesting error (full data):\t\t0.31302\n",
      "Using 1.38% of the training set  (coreset of 1963 examples):\n",
      "\tTesting error (original coreset):\t0.68244\n",
      "\tTesting error (smoothed coreset):\t0.82171\n",
      "\tTesting error (uniform sample):\t\t0.47152\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
